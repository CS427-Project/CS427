{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import torch.utils.data as data\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from data import WiderFaceDetection, detection_collate, preproc, cfg_mnet, cfg_re50\n",
    "from layers.modules import MultiBoxLoss\n",
    "from layers.functions.prior_box import PriorBox\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from models.retinaface import RetinaFace\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare config (use resnet50 backbone)\n",
    "cfg = cfg_re50\n",
    "rgb_mean = (104, 117, 123) # bgr order\n",
    "num_classes = 2\n",
    "img_dim = cfg['image_size']\n",
    "num_gpu = cfg['ngpu']\n",
    "batch_size = cfg['batch_size']\n",
    "max_epoch = cfg['epoch']\n",
    "gpu_train = cfg['gpu_train']\n",
    "\n",
    "initial_lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with the configurations above\n",
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}\n",
    "\n",
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=device)\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model\n",
    "\n",
    "model = RetinaFace(cfg=cfg, phase=\"test\").to(device)\n",
    "model = load_model(model, \"../Resnet50_Final.pth\", False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 1000 non-member images and 1000 member images\n",
    "category = os.listdir(\"../data/widerface/val/images/\")\n",
    "non_member_images = []\n",
    "for i in range(50):\n",
    "    folder = os.listdir(f\"../data/widerface/val/images/{category[i]}/\")\n",
    "    for j in range(19):\n",
    "        print(category[i])\n",
    "        image_path = f\"../data/widerface/val/images/{category[i]}/{folder[j]}\"\n",
    "        non_member_images.append(image_path)\n",
    "\n",
    "category = os.listdir(\"../data/widerface/train/images/\")\n",
    "member_images = []\n",
    "for i in range(50):\n",
    "    folder = os.listdir(f\"../data/widerface/train/images/{category[i]}/\")\n",
    "    for j in range(19):\n",
    "        image_path = f\"../data/widerface/train/images/{category[i]}/{folder[j]}\"\n",
    "        member_images.append(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
