{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import torch.utils.data as data\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from data import WiderFaceDetection, detection_collate, preproc, cfg_mnet, cfg_re50\n",
    "from layers.modules import MultiBoxLoss\n",
    "from layers.functions.prior_box import PriorBox\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from models.retinaface import RetinaFace\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare config (use resnet50 backbone)\n",
    "cfg = cfg_re50\n",
    "rgb_mean = (104, 117, 123) # bgr order\n",
    "num_classes = 2\n",
    "img_dim = cfg['image_size']\n",
    "num_gpu = cfg['ngpu']\n",
    "batch_size = cfg['batch_size']\n",
    "max_epoch = cfg['epoch']\n",
    "gpu_train = cfg['gpu_train']\n",
    "\n",
    "initial_lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calvin/Documents/smu/Y3S2/CS427/CS427/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/calvin/Documents/smu/Y3S2/CS427/CS427/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ../Resnet50_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RetinaFace(\n",
       "  (body): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fpn): FPN(\n",
       "    (output1): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "    (output2): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "    (output3): Sequential(\n",
       "      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "    (merge1): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "    (merge2): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (ssh1): SSH(\n",
       "    (conv3X3): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv5X5_1): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "    (conv5X5_2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv7X7_2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "    (conv7x7_3): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (ssh2): SSH(\n",
       "    (conv3X3): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv5X5_1): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "    (conv5X5_2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv7X7_2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "    (conv7x7_3): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (ssh3): SSH(\n",
       "    (conv3X3): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv5X5_1): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "    (conv5X5_2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv7X7_2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    )\n",
       "    (conv7x7_3): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (ClassHead): ModuleList(\n",
       "    (0-2): 3 x ClassHead(\n",
       "      (conv1x1): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (BboxHead): ModuleList(\n",
       "    (0-2): 3 x BboxHead(\n",
       "      (conv1x1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (LandmarkHead): ModuleList(\n",
       "    (0-2): 3 x LandmarkHead(\n",
       "      (conv1x1): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model with the configurations above\n",
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}\n",
    "\n",
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=device)\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model\n",
    "\n",
    "model = RetinaFace(cfg=cfg, phase=\"test\").to(device)\n",
    "model = load_model(model, \"../Resnet50_Final.pth\", False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 1000 non-member images and 1000 member images\n",
    "category = os.listdir(\"../data/widerface/val/images/\")\n",
    "non_member_images = []\n",
    "for i in range(50):\n",
    "    folder = os.listdir(f\"../data/widerface/val/images/{category[i]}/\")\n",
    "    for j in range(19):\n",
    "        image_path = f\"../data/widerface/val/images/{category[i]}/{folder[j]}\"\n",
    "        non_member_images.append(image_path)\n",
    "\n",
    "category = os.listdir(\"../data/widerface/train/images/\")\n",
    "member_images = []\n",
    "for i in range(50):\n",
    "    folder = os.listdir(f\"../data/widerface/train/images/{category[i]}/\")\n",
    "    for j in range(19):\n",
    "        image_path = f\"../data/widerface/train/images/{category[i]}/{folder[j]}\"\n",
    "        member_images.append(image_path)\n",
    "\n",
    "all_images = non_member_images + member_images\n",
    "labels = [0] * len(non_member_images) + [1] * len(member_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction from RetinaFace\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "from utils.box_utils import decode, decode_landm\n",
    "\n",
    "def test_forward_pass(image_path, model, confidence_threshold):\n",
    "    resize = 1\n",
    "    img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    img = np.float32(img_raw)\n",
    "\n",
    "    im_height, im_width, _ = img.shape\n",
    "    scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "    img -= (104, 117, 123)\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    scale = scale.to(device)\n",
    "    loc, conf, landms = model(img)  # forward pass\n",
    "\n",
    "    priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "    priors = priorbox.forward()\n",
    "    priors = priors.to(device)\n",
    "    prior_data = priors.data\n",
    "\n",
    "    boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    boxes = boxes * scale / resize\n",
    "    boxes = boxes.cpu().numpy()\n",
    "\n",
    "    scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "    landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "\n",
    "    scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                               img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                               img.shape[3], img.shape[2]])\n",
    "    scale1 = scale1.to(device)\n",
    "    landms = landms * scale1 / resize\n",
    "    landms = landms.cpu().numpy()\n",
    "\n",
    "    # ignore low scores\n",
    "    inds = np.where(scores > confidence_threshold)[0]\n",
    "    boxes = boxes[inds]\n",
    "    landms = landms[inds]\n",
    "    scores = scores[inds]\n",
    "\n",
    "    # keep top-K before NMSk\n",
    "    top_k = 5000\n",
    "    order = scores.argsort()[::-1][:top_k]\n",
    "    boxes = boxes[order]\n",
    "    landms = landms[order]\n",
    "    scores = scores[order]\n",
    "\n",
    "    # do NMS\n",
    "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    nms_threshold = 0.4\n",
    "    keep = py_cpu_nms(dets, nms_threshold)\n",
    "    # keep = nms(dets, args.nms_threshold,force_cpu=args.cpu)\n",
    "    dets = dets[keep, :]\n",
    "    landms = landms[keep]\n",
    "\n",
    "    # keep top-K faster NMS\n",
    "    keep_top_k = 750\n",
    "    dets = dets[:keep_top_k, :]\n",
    "    landms = landms[:keep_top_k, :]\n",
    "\n",
    "    dets = np.concatenate((dets, landms), axis=1)\n",
    "    return dets\n",
    "\n",
    "def extract_retinaface_features(image_path, model, confidence_threshold):\n",
    "\n",
    "    dets = test_forward_pass(image_path, model, confidence_threshold)\n",
    "\n",
    "    if dets is None or len(dets) == 0:\n",
    "        return [0, 0, 0, 0]\n",
    "    \n",
    "    confidences = dets[:, 4]\n",
    "    num_faces = len(confidences)\n",
    "\n",
    "    max_conf = float(np.max(confidences))\n",
    "    avg_conf = float(np.mean(confidences))\n",
    "\n",
    "    sum_conf = np.sum(confidences)\n",
    "    normalized = confidences / (sum_conf + 1e-9)\n",
    "    entropy = -np.sum(normalized * np.log(normalized + 1e-9))\n",
    "\n",
    "    return [num_faces, max_conf, avg_conf, entropy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "Feature Shape: (1900, 4)\n",
      "Labels Shape: (1900,)\n"
     ]
    }
   ],
   "source": [
    "# Build attack dataset\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "count = 0\n",
    "for img_path, label in zip(all_images, labels):\n",
    "    features = extract_retinaface_features(img_path, model, 0.5)\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "    count += 1\n",
    "\n",
    "    if count % 10 == 0:\n",
    "        print(count)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Feature Shape:\", x.shape)\n",
    "print(\"Labels Shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the attack model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if os.path.exists(\"attack_dataset.npz\"):\n",
    "    data = np.load(\"attack_dataset.npz\")\n",
    "    x, y = data['x'], data['y']\n",
    "else:\n",
    "    # your feature extraction loop\n",
    "    np.savez(\"attack_dataset.npz\", x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Model Accuracy on Test: 0.486\n",
      "Attack Model AUC on Test:      0.504\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "attack_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "attack_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = attack_model.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, attack_model.predict_proba(x_test)[:,1])\n",
    "print(f\"Attack Model Accuracy on Test: {acc:.3f}\")\n",
    "print(f\"Attack Model AUC on Test:      {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CIFAR10 ####\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "class ClassifierNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 8)\n",
    "        self.fc5 = nn.Linear(8, 4)\n",
    "        self.fc6 = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def save_model(model, name):\n",
    "    torch.save(model.state_dict(), name)\n",
    "\n",
    "\n",
    "def load_model(model_class, name, *args):\n",
    "    model = model_class(*args)\n",
    "    model.load_state_dict(torch.load(name, map_location=torch.device(device)))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model, dataloader, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print('loss: {:.4f} [{}/{}]'.format(loss, current, size))\n",
    "\n",
    "\n",
    "def print_model(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name)\n",
    "        print(param.data)\n",
    "\n",
    "\n",
    "def test(model, dataloader, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    loss, correct = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "\n",
    "            loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.int).sum().item()\n",
    "\n",
    "    loss /= num_batches\n",
    "    correct /= size\n",
    "    print('Test Error: \\n Accuracy: {:.2f}%, Avg loss: {:.4f}\\n'.format(100 * correct, loss))\n",
    "\n",
    "    return correct / size\n",
    "\n",
    "#the following function evaluates the precision and recall of the member predictor.\n",
    "def precisionAndRecall(model, dataloader, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    #pred_member is the number of samples that are predicted as members (TP + FP)\n",
    "    #real_member is the number of samles that are predicted as members and are members indeed. (TP)\n",
    "    #all_member (TP + FN predict as non-memb but is memb)\n",
    "    pred_member, real_member, all_member = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "\n",
    "            pred_member += (pred.argmax(1) == 1).type(torch.int).sum().item()\n",
    "            real_member += (torch.logical_and(pred.argmax(1) == 1, pred.argmax(1) == y)).type(torch.int).sum().item()\n",
    "            all_member += (y == 1).type(torch.int).sum().item()\n",
    "\n",
    "    #TODO: compute the precision (tp/tp+fp)\n",
    "    false_pos = pred_member - real_member\n",
    "    precision = real_member / (real_member + false_pos)\n",
    "    print('Precision: {:.2f}%\\n'.format(100 * precision))\n",
    "    #TODO: compute the recall (tp/tp+fn)\n",
    "    false_neg = all_member - real_member\n",
    "    recall = real_member / (real_member + false_neg)\n",
    "    print('Recall: {:.2f}%\\n'.format(100 * recall))\n",
    "\n",
    "\n",
    "def get_loader(data_file, kwargs):\n",
    "    data_file = open(data_file, 'r')\n",
    "    input_data, label_data = [], []\n",
    "\n",
    "    for line in data_file.readlines():\n",
    "        data = ast.literal_eval(line)\n",
    "        input_data.append(data[:-1])\n",
    "        label_data.append(data[-1])\n",
    "\n",
    "    input_data = np.array(input_data)\n",
    "    label_data = np.array(label_data)\n",
    "\n",
    "    input_data_tensor = torch.Tensor(input_data)\n",
    "    label_data_tensor = torch.Tensor(label_data).type(torch.LongTensor)\n",
    "\n",
    "    dataset = TensorDataset(input_data_tensor, label_data_tensor)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, shuffle=True, **kwargs)\n",
    "\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your numpy arrays to PyTorch tensors\n",
    "x_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Build a TensorDataset\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Make your DataLoaders\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_ds, test_ds = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 0 ---\n",
      "\n",
      "loss: 0.7980 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.7367\n",
      "\n",
      "\n",
      "--- Epoch 1 ---\n",
      "\n",
      "loss: 0.7370 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.7194\n",
      "\n",
      "\n",
      "--- Epoch 2 ---\n",
      "\n",
      "loss: 0.7339 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.7092\n",
      "\n",
      "\n",
      "--- Epoch 3 ---\n",
      "\n",
      "loss: 0.6550 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.7025\n",
      "\n",
      "\n",
      "--- Epoch 4 ---\n",
      "\n",
      "loss: 0.7247 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6982\n",
      "\n",
      "\n",
      "--- Epoch 5 ---\n",
      "\n",
      "loss: 0.6808 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6955\n",
      "\n",
      "\n",
      "--- Epoch 6 ---\n",
      "\n",
      "loss: 0.7181 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6938\n",
      "\n",
      "\n",
      "--- Epoch 7 ---\n",
      "\n",
      "loss: 0.7202 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6928\n",
      "\n",
      "\n",
      "--- Epoch 8 ---\n",
      "\n",
      "loss: 0.7174 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6922\n",
      "\n",
      "\n",
      "--- Epoch 9 ---\n",
      "\n",
      "loss: 0.6724 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6919\n",
      "\n",
      "\n",
      "--- Epoch 10 ---\n",
      "\n",
      "loss: 0.7025 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6918\n",
      "\n",
      "\n",
      "--- Epoch 11 ---\n",
      "\n",
      "loss: 0.6890 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6918\n",
      "\n",
      "\n",
      "--- Epoch 12 ---\n",
      "\n",
      "loss: 0.6875 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6919\n",
      "\n",
      "\n",
      "--- Epoch 13 ---\n",
      "\n",
      "loss: 0.6938 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6920\n",
      "\n",
      "\n",
      "--- Epoch 14 ---\n",
      "\n",
      "loss: 0.6937 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6922\n",
      "\n",
      "\n",
      "--- Epoch 15 ---\n",
      "\n",
      "loss: 0.6948 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6924\n",
      "\n",
      "\n",
      "--- Epoch 16 ---\n",
      "\n",
      "loss: 0.6956 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6925\n",
      "\n",
      "\n",
      "--- Epoch 17 ---\n",
      "\n",
      "loss: 0.6959 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.63%, Avg loss: 0.6926\n",
      "\n",
      "\n",
      "--- Epoch 18 ---\n",
      "\n",
      "loss: 0.6918 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.89%, Avg loss: 0.6927\n",
      "\n",
      "\n",
      "--- Epoch 19 ---\n",
      "\n",
      "loss: 0.6929 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 52.37%, Avg loss: 0.6928\n",
      "\n",
      "\n",
      "--- Epoch 20 ---\n",
      "\n",
      "loss: 0.6925 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 51.58%, Avg loss: 0.6929\n",
      "\n",
      "\n",
      "--- Epoch 21 ---\n",
      "\n",
      "loss: 0.6933 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 51.05%, Avg loss: 0.6930\n",
      "\n",
      "\n",
      "--- Epoch 22 ---\n",
      "\n",
      "loss: 0.6940 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 51.84%, Avg loss: 0.6931\n",
      "\n",
      "\n",
      "--- Epoch 23 ---\n",
      "\n",
      "loss: 0.6929 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 51.05%, Avg loss: 0.6932\n",
      "\n",
      "\n",
      "--- Epoch 24 ---\n",
      "\n",
      "loss: 0.6930 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 51.05%, Avg loss: 0.6932\n",
      "\n",
      "\n",
      "--- Epoch 25 ---\n",
      "\n",
      "loss: 0.6935 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6933\n",
      "\n",
      "\n",
      "--- Epoch 26 ---\n",
      "\n",
      "loss: 0.6935 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6933\n",
      "\n",
      "\n",
      "--- Epoch 27 ---\n",
      "\n",
      "loss: 0.6934 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6934\n",
      "\n",
      "\n",
      "--- Epoch 28 ---\n",
      "\n",
      "loss: 0.6928 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6935\n",
      "\n",
      "\n",
      "--- Epoch 29 ---\n",
      "\n",
      "loss: 0.6931 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6935\n",
      "\n",
      "\n",
      "--- Epoch 30 ---\n",
      "\n",
      "loss: 0.6928 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6935\n",
      "\n",
      "\n",
      "--- Epoch 31 ---\n",
      "\n",
      "loss: 0.6931 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6936\n",
      "\n",
      "\n",
      "--- Epoch 32 ---\n",
      "\n",
      "loss: 0.6935 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6936\n",
      "\n",
      "\n",
      "--- Epoch 33 ---\n",
      "\n",
      "loss: 0.6900 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6936\n",
      "\n",
      "\n",
      "--- Epoch 34 ---\n",
      "\n",
      "loss: 0.6925 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6936\n",
      "\n",
      "\n",
      "--- Epoch 35 ---\n",
      "\n",
      "loss: 0.6935 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6936\n",
      "\n",
      "\n",
      "--- Epoch 36 ---\n",
      "\n",
      "loss: 0.6928 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6936\n",
      "\n",
      "\n",
      "--- Epoch 37 ---\n",
      "\n",
      "loss: 0.6936 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6936\n",
      "\n",
      "\n",
      "--- Epoch 38 ---\n",
      "\n",
      "loss: 0.6942 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6936\n",
      "\n",
      "\n",
      "--- Epoch 39 ---\n",
      "\n",
      "loss: 0.6943 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6937\n",
      "\n",
      "\n",
      "--- Epoch 40 ---\n",
      "\n",
      "loss: 0.6934 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6937\n",
      "\n",
      "\n",
      "--- Epoch 41 ---\n",
      "\n",
      "loss: 0.6932 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6936\n",
      "\n",
      "\n",
      "--- Epoch 42 ---\n",
      "\n",
      "loss: 0.6945 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6937\n",
      "\n",
      "\n",
      "--- Epoch 43 ---\n",
      "\n",
      "loss: 0.6888 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6937\n",
      "\n",
      "\n",
      "--- Epoch 44 ---\n",
      "\n",
      "loss: 0.6940 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6937\n",
      "\n",
      "\n",
      "--- Epoch 45 ---\n",
      "\n",
      "loss: 0.6940 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6937\n",
      "\n",
      "\n",
      "--- Epoch 46 ---\n",
      "\n",
      "loss: 0.6935 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6937\n",
      "\n",
      "\n",
      "--- Epoch 47 ---\n",
      "\n",
      "loss: 0.6924 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6937\n",
      "\n",
      "\n",
      "--- Epoch 48 ---\n",
      "\n",
      "loss: 0.6947 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6938\n",
      "\n",
      "\n",
      "--- Epoch 49 ---\n",
      "\n",
      "loss: 0.6935 [0/1520]\n",
      "Test Error: \n",
      " Accuracy: 47.63%, Avg loss: 0.6938\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.89%, Avg loss: 0.6927\n",
      "\n",
      "Precision: 52.66%\n",
      "\n",
      "Recall: 99.50%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ClassifierNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 3) Training loop\n",
    "num_of_epochs = 50\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_of_epochs):\n",
    "    print(f'\\n--- Epoch {epoch} ---\\n')\n",
    "    train(model, train_loader, loss_fn, optimizer, device)\n",
    "    acc = test(model, test_loader, loss_fn, device)\n",
    "    \n",
    "    # Save best model\n",
    "    if acc > best_acc:\n",
    "        save_model(model, \"mia_classifier.pt\")\n",
    "        best_acc = acc\n",
    "\n",
    "# 4) Reload the best model and do a final test\n",
    "model = load_model(ClassifierNet, \"mia_classifier.pt\")\n",
    "model = model.to(device)\n",
    "test(model, test_loader, loss_fn, device)\n",
    "\n",
    "# 5) Evaluate precision and recall\n",
    "precisionAndRecall(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
