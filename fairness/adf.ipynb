{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "163d04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from future import print_function\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import torch.utils.data as data\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from data import WiderFaceDetection, detection_collate, preproc, cfg_mnet, cfg_re50\n",
    "from layers.modules import MultiBoxLoss\n",
    "from layers.functions.prior_box import PriorBox\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from models.retinaface import RetinaFace\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5318600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare config (use resnet50 backbone)\n",
    "cfg = cfg_re50\n",
    "rgb_mean = (104, 117, 123) # bgr order\n",
    "num_classes = 2\n",
    "img_dim = cfg['image_size']\n",
    "num_gpu = cfg['ngpu']\n",
    "batch_size = cfg['batch_size']\n",
    "max_epoch = cfg['epoch']\n",
    "gpu_train = cfg['gpu_train']\n",
    "\n",
    "initial_lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92085544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Female Images: 40758\n",
      "Number of Male Images: 45986\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"../data/fairface/fairface_label_train.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Separate male and female images\n",
    "female_images = df[df[\"gender\"] == 'Female']['file'].tolist()\n",
    "male_images = df[df['gender'] == 'Male']['file'].tolist()\n",
    "\n",
    "print(f\"Number of Female Images: {len(female_images)}\")\n",
    "print(f\"Number of Male Images: {len(male_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747afaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with the configurations above\n",
    "model = RetinaFace(cfg=cfg).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe8684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    detections = model.detect_faces(image)\n",
    "\n",
    "    if detections:\n",
    "        return len(detections), [d['score'] for d in detections]\n",
    "    return 0, []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
